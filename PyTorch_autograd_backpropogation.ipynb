{"cells":[{"cell_type":"markdown","metadata":{"id":"axN9Fs5aKiQR"},"source":["# <font color = 'pickle'>**HW3 - 15 Points** </font>\n","\n","1. For Questions (1, 2 and 3) you will submit two files: a) A colab notebook b) A well formatted PDF file.\n","2. The notebook and pdf files should contain all the output.\n","3. For Question 4 - submit a pdf OR ppt file.\n","4. Name the files as follows : FirstName_hw3.ipynb, FirstName_hw3.pdf\n","5. If the submission requires multiple files name them as follows: FirstName_file1_hw3, FirstName_file2_hw3.\n"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":189,"status":"ok","timestamp":1665560018006,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"fClzRGrtCT74"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{"id":"Ea_kC8Jy0sE8"},"source":["# <font color = 'pickle'>**Q1. Compute Gradient using  PyTorch Autograd - 2 Points**\n","## $f(x,y) = \\frac{x + \\exp(y)}{\\log(x) + (x-y)^3}$\n","Compute dx and dy at x=3 and y=4"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665560018007,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"rcDTwteKbZUH"},"outputs":[],"source":["def fxy(x,y):\n","  num = x + torch.exp(y)\n","  den = torch.log(x) + (x-y)**3\n","  return num/den"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665560018007,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"0ADHy2FqfP8S"},"outputs":[],"source":["x = torch.tensor([3.0], requires_grad=True)\n","y = torch.tensor([4.0], requires_grad=True)"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665560018109,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"_2HFXif6fg7A","outputId":"01b351d9-d860-4c0a-c351-6173cce9d2c9"},"outputs":[{"data":{"text/plain":["tensor([584.0868], grad_fn=<DivBackward0>)"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["f = fxy(x,y)\n","f"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665560018110,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"TbZiDeTXfrLf"},"outputs":[],"source":["f.backward()"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665560018110,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"7al8BVZKf3R7","outputId":"209944af-2953-46c5-f534-49091dcf0ad1"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([-19733.3965]) tensor([18322.8477])\n"]}],"source":["print(x.grad, y.grad)"]},{"cell_type":"markdown","metadata":{"id":"BYYL_jnG0B3i"},"source":["# <font color = 'pickle'>**Q2. Regression with autogard (backward() method) 5 points** </font>\n","\n","<font size = 4,  color ='indianred'> **Redo  question 7 from HW1. Now we will use Pytorch's autograd to calculate the gradients instead of manually calculating gradients.**</font>\n","\n","\n","Imagine that you're trying to figure out relationship between two variables x and y . You have some idea but you aren't quite sure yet whether the dependence is linear or quadratic. \n","\n","Your goal is to use least mean squares regression to identify the coefficients for the following three models :\n","\n","1. Quadratic model where $\\mathrm{y} = b + w_1 \\cdot \\mathrm{x} + w_2 \\cdot \\mathrm{x}^2$.\n","1. Linear model where $\\mathrm{y} = b + w_1 \\cdot \\mathrm{x}$.\n","1. Linear model with no bias  where $\\mathrm{y} = w_1 \\cdot \\mathrm{x}$.\n","\n","\n","- You will use batch gradient descent to estimate the model co-efficients. Batch gradient descent uses complete training data at each iteration. \n","- We will implement only training loop (no splitting of data in to training/validation).\n","- The training loop will have only one for loop. We need to iterate over whole data in each epoch. We do not need to create batches.\n","- You may have to try different values of number of epochs/ learning rate to get good results.\n","- <font color = 'indianred'>**You are not allowed to use Pytorch's nn.module or functions from Pytorch. You will write function for loss function (mean sqaured error), and prediction from scratch.**</font>\n","- <font color = 'indianred'>**You will not calculate gradients manually. You will use backward() method to compute gradients.**"]},{"cell_type":"markdown","metadata":{"id":"JShaYAruM_9F"},"source":["## <font color = 'pickle'> **Data**"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665560018110,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"xM9NZIJyJPXJ"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665560018110,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"WUcQ0mpp3HNm"},"outputs":[],"source":["x = torch.tensor([1.5420291, 1.8935232, 2.1603365, 2.5381863, 2.893443, \\\n","                    3.838855, 3.925425, 4.2233696, 4.235571, 4.273397, \\\n","                    4.9332876, 6.4704757, 6.517571, 6.87826, 7.0009003, \\\n","                    7.035741, 7.278681, 7.7561755, 9.121138, 9.728281])\n","y = torch.tensor([63.802246, 80.036026, 91.4903, 108.28776, 122.781975, \\\n","                    161.36314, 166.50816, 176.16772, 180.29395, 179.09758, \\\n","                    206.21027, 272.71857, 272.24033, 289.54745, 293.8488, \\\n","                    295.2281, 306.62274, 327.93243, 383.16296, 408.65967])"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665560018110,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"SIz014acHLid"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665560018110,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"rANPOz2gM6jM"},"outputs":[],"source":["y = y.view(-1, 1)\n","x = x.view(-1, 1)\n","x2 = x*x"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":114,"status":"ok","timestamp":1665560018222,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"hqQS3ENqNE2l"},"outputs":[],"source":["x_combined = torch.cat((x, x2), dim = 1)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665560018222,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"S50TcA7JNNtK","outputId":"43926740-96fc-4331-90c6-7eef0c7e1319"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([20, 2]) torch.Size([20, 1])\n"]}],"source":["print(x_combined.shape, x.shape)"]},{"cell_type":"markdown","metadata":{"id":"QOXjRegsNZXM"},"source":["## <font color = 'pickle'> **Utility Functions**"]},{"cell_type":"markdown","metadata":{"id":"q1SCuro_IxmQ"},"source":["### <font color = 'pickle'>**Model Linear Regression**"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":93,"status":"ok","timestamp":1665560018313,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"8Y8HcA9WIwbj"},"outputs":[],"source":["def linear_reg(x, w, b, bias):\n","  if bias: \n","    return torch.mm(x, w.T) + b\n","  else: \n","    return torch.mm(x, w.T)"]},{"cell_type":"markdown","metadata":{"id":"Nj5YZj9-NiRl"},"source":["### <font color = 'pickle'>**Loss Function**"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665560018314,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"CyCFabCOOONL"},"outputs":[],"source":["def mse_loss(y, yhat):\n","  error = yhat - y\n","  square_loss = torch.mm(error.T, error)\n","  return square_loss/len(y)"]},{"cell_type":"markdown","metadata":{"id":"BsLikIXx-KTB"},"source":["### <font color = 'pickle'> **Gradient Linear Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQg-Db4w-WCW"},"outputs":[],"source":["'''\n","def lin_grad(x, y, y_hat, bias= True):\n","  error = y_hat - y\n","  print(len(y))\n","  w_grad = ( torch.mm(x.T, error))/ len(y) # shape is (x.shape[-1], n_outs) \n","  if bias:\n","    b_grad =  error.sum() /len(y)\n","    return (w_grad.T, b_grad)\n","  else:\n","    return w_grad.T  # reshape to  (n_outs, x.shape[-1]) \n","  '''"]},{"cell_type":"markdown","metadata":{"id":"HA0l2cQ8NLxS"},"source":["### <font color = 'pickle'> **Optimizer**"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665560018314,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"5MaGGW43PNCA"},"outputs":[],"source":["def sgd_step(params, learning_rate):\n","  with torch.no_grad():\n","    for param in params:\n","      param.data -= learning_rate * param.grad    \n","      param.grad.zero_() "]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665560018314,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"MCjMJLscxeGM","outputId":"a352c0c4-70cd-46f0-fb88-fc55d072b293"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ndef sgd_step(params, param_grads, learning_rate):\\n  for param, param_grad in zip(params, param_grads):\\n    param -= learning_rate*param_grad\\n'"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","def sgd_step(params, param_grads, learning_rate):\n","  for param, param_grad in zip(params, param_grads):\n","    param -= learning_rate*param_grad\n","'''    "]},{"cell_type":"markdown","metadata":{"id":"BbT4Z89HHvPb"},"source":["### <font color = 'pickle'> **Train Function**"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665560018315,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"FSJU5UgpNy6b"},"outputs":[],"source":["def train(epochs, x, y, n_outs, bias, loss_function, log_interval, learning_rate):\n","  loss_epoch = []\n","  n_ins = x.shape[-1]\n","  w = torch.normal(0, 0.01, size=(n_outs, n_ins), requires_grad=True)\n","  b = torch.zeros(n_outs, requires_grad=True)\n","  \n","  if bias ==True:\n","    params = [w,b]\n","  else:\n","    params = [w]\n","\n","\n","  for epoch in range(epochs):\n","    \n","    # Step1: forward pass\n","    y_hat = linear_reg(x, w, b, bias)\n","\n","    # Step2 : Loss\n","    loss = loss_function(y_hat, y)\n","\n","    # Calculate Gradients\n","    # param_grads = lin_grad(x, y, y_hat, bias)\n","    loss.backward()\n","    \n","    # update parameters\n","    # sgd_step(params, param_grads, learning_rate) \n","    sgd_step(params, learning_rate) \n","\n","    if(epoch % log_interval ==0):\n","      print(f'epoch: {epoch + 1} --> loss {loss.item()}')\n","\n","  return (w, b) \n"," "]},{"cell_type":"markdown","metadata":{"id":"xns2sBYJm0dj"},"source":["## <font color = 'pickle'> **Part 1**"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19204,"status":"ok","timestamp":1665560037514,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"utgwb7HyRZkm","outputId":"297f6ec9-2349-4af5-d2af-2768bc889aa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 1 --> loss 58004.09375\n","epoch: 10001 --> loss 5.000570774078369\n","epoch: 20001 --> loss 3.0938141345977783\n","epoch: 30001 --> loss 2.1370463371276855\n","epoch: 40001 --> loss 1.6568940877914429\n","epoch: 50001 --> loss 1.4159462451934814\n","epoch: 60001 --> loss 1.2948728799819946\n","epoch: 70001 --> loss 1.2340748310089111\n","epoch: 80001 --> loss 1.2035744190216064\n","epoch: 90001 --> loss 1.1881871223449707\n"]}],"source":["# model 1  \n","loss_function = mse_loss\n","LEARNING_RATE = 0.0005\n","EPOCHS = 100000\n","LOG_INTERVAL= 10000\n","N_OUTS = 1\n","BIAS = True\n","\n","w1, b1 = train(EPOCHS, x_combined, y,  N_OUTS, BIAS, loss_function, LOG_INTERVAL, LEARNING_RATE)"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665560037514,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"vYu7XpVUXe6F","outputId":"533ca5ff-e0ae-4fcf-b39c-80a9859ffd65"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Weights tensor([[4.1796e+01, 1.4825e-02]], requires_grad=True), \n","Bias: tensor([0.9772], requires_grad=True)\n"]}],"source":["print(f' Weights {w1}, \\nBias: {b1}')"]},{"cell_type":"markdown","metadata":{"id":"yjBjky9Hm7Up"},"source":["## <font color = 'pickle'> **Part 2**"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1665560037768,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ELy7vX8Fm7Up","outputId":"991c767a-b7ed-4a64-bc3b-4ad4d8c2e80f"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 1 --> loss 57934.76953125\n","epoch: 101 --> loss 4.354974269866943\n","epoch: 201 --> loss 2.806662082672119\n","epoch: 301 --> loss 2.01165509223938\n","epoch: 401 --> loss 1.6034339666366577\n","epoch: 501 --> loss 1.3938376903533936\n","epoch: 601 --> loss 1.2862128019332886\n","epoch: 701 --> loss 1.2309529781341553\n","epoch: 801 --> loss 1.2025809288024902\n","epoch: 901 --> loss 1.1880155801773071\n"]}],"source":["# model 2\n","loss_function = mse_loss\n","LEARNING_RATE = 0.01\n","EPOCHS = 1000\n","LOG_INTERVAL= 100\n","N_OUTS = 1\n","BIAS = True\n","\n","w2, b2 = train(EPOCHS, x, y,  N_OUTS, BIAS, loss_function, LOG_INTERVAL, LEARNING_RATE)"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1665560037925,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"hrd64AY7m7Up","outputId":"5b891e26-3961-45d3-b801-b9f9d209e8db"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Weights tensor([[41.9377]], requires_grad=True), \n","Bias: tensor([0.7467], requires_grad=True)\n"]}],"source":["print(f' Weights {w2}, \\nBias: {b2}')"]},{"cell_type":"markdown","metadata":{"id":"wE91_Rg8nmSu"},"source":["## <font color = 'pickle'> **Part 3**"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665560037925,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"-3QSWacbnmSu","outputId":"b2c0a2f5-6926-4982-801d-1425d80a3021"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 1 --> loss 57980.26171875\n","epoch: 2 --> loss 6897.80859375\n","epoch: 3 --> loss 821.5675659179688\n","epoch: 4 --> loss 98.80074310302734\n","epoch: 5 --> loss 12.828018188476562\n","epoch: 6 --> loss 2.6015257835388184\n","epoch: 7 --> loss 1.385072946548462\n","epoch: 8 --> loss 1.2403770685195923\n","epoch: 9 --> loss 1.223166584968567\n","epoch: 10 --> loss 1.2211220264434814\n"]}],"source":["# model 2\n","loss_function = mse_loss\n","LEARNING_RATE = 0.01\n","EPOCHS = 10\n","LOG_INTERVAL= 1\n","N_OUTS = 1\n","BIAS = False\n","\n","w3, b3 = train(EPOCHS, x, y,  N_OUTS, BIAS, loss_function, LOG_INTERVAL, LEARNING_RATE)"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665560037926,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"s7a2F_GZnmSu","outputId":"605c867a-08ec-4558-f710-b7da74c3546c"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Weights tensor([[42.0557]], requires_grad=True), \n","Bias: tensor([0.], requires_grad=True)\n"]}],"source":["print(f' Weights {w3}, \\nBias: {b3}')"]},{"cell_type":"markdown","metadata":{"id":"RX5yKE-t0sEn"},"source":["# <font color = 'pickle'>**Q 3. Numerical Precision - 3 Points**\n","\n","Given scalars `x` and `y`, implement the following `log_exp` function such that it returns \n","$$-\\log\\left(\\frac{e^x}{e^x+e^y}\\right)$$."]},{"cell_type":"code","execution_count":63,"metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.206890Z","start_time":"2019-01-29T22:48:56.202996Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665560037926,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"nikSfenDC3c3"},"outputs":[],"source":["#Question\n","def log_exp(x, y):\n","    ## add your solution here and remove pass\n","    return -torch.log(torch.exp(x)/(torch.exp(x)+ torch.exp(y)))\n","    #pass"]},{"cell_type":"markdown","metadata":{"id":"ada0LKKYC3c3"},"source":["Test your codes with normal inputs:"]},{"cell_type":"code","execution_count":64,"metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.215579Z","start_time":"2019-01-29T22:48:56.209659Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665560037926,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"oIZ0UETBC3c3","outputId":"d464d4d0-c865-43d5-b488-70af7d50bce2"},"outputs":[{"data":{"text/plain":["tensor([1.3133])"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["x, y = torch.tensor([2.0]), torch.tensor([3.0])\n","z = log_exp(x, y)\n","z"]},{"cell_type":"markdown","metadata":{"id":"sbGtCaQ6C3c4"},"source":["Now implement a function to compute $\\partial z/\\partial x$ and $\\partial z/\\partial y$ with `autograd`"]},{"cell_type":"code","execution_count":65,"metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.223303Z","start_time":"2019-01-29T22:48:56.218056Z"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665560037926,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"2kMC5IdJC3c4"},"outputs":[],"source":["def grad(forward_func, x, y): \n","  x.requires_grad_()\n","  y.requires_grad_()\n","  \n","  ## Add your codes here\n","  z=forward_func(x,y)\n","  z.backward()\n","\n","  ## your code ends here\n","  print('x.grad =', x.grad)\n","  print('y.grad =', y.grad)\n","  x.grad.zero_()\n","  y.grad.zero_()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"g5Q3d5opC3c4"},"source":["Test your codes, it should print the results nicely. "]},{"cell_type":"code","execution_count":66,"metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.267165Z","start_time":"2019-01-29T22:48:56.227035Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665560038083,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"oob8ND3BC3c4","outputId":"df8894bd-22d6-4ba3-9f6b-81b26eb9a341"},"outputs":[{"name":"stdout","output_type":"stream","text":["x.grad = tensor([-0.7311])\n","y.grad = tensor([0.7311])\n"]}],"source":["grad(log_exp, x, y)"]},{"cell_type":"markdown","metadata":{"id":"L4nMM2joC3c4"},"source":["But now let's try some \"hard\" inputs"]},{"cell_type":"code","execution_count":67,"metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.285842Z","start_time":"2019-01-29T22:48:56.274079Z"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1665560038083,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"d_f5Xk41C3c4"},"outputs":[],"source":["x, y = torch.tensor([50.0]), torch.tensor([100.0])"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665560038084,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ECgqQ_i-C3c4","outputId":"d97a8b14-a118-4a9e-cb8e-9898f73270d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["x.grad = tensor([nan])\n","y.grad = tensor([nan])\n"]}],"source":["grad(log_exp, x, y)"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1665560038084,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"kHsyDVblC3c4","outputId":"5245b0ce-8b90-44d1-df90-47c334bd10fe"},"outputs":[{"data":{"text/plain":["tensor([inf])"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["torch.exp(torch.tensor([100.0]))"]},{"cell_type":"markdown","metadata":{"id":"clK0zCMjC3c4"},"source":["Does your code return correct results? If not, try to understand the reason. (Hint, evaluate `exp(100)`). Now develop a new function `stable_log_exp` that is identical to `log_exp` in math, but returns a more numerical stable result.\n","<br> Hint: (1) $\\log\\left(\\frac{x}{y}\\right) = log ({x}) -log({y})$\n","<br> Hint: (2) See logsum Trick - https://www.xarg.org/2016/06/the-log-sum-exp-trick-in-machine-learning/"]},{"cell_type":"code","execution_count":70,"metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.305595Z","start_time":"2019-01-29T22:48:56.293399Z"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1665560038084,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"alymet8aC3c4"},"outputs":[],"source":["def stable_log_exp(x, y):\n","    ## Add your codes here)\n","    z=torch.max(x,y)\n","    return -x + z + torch.log(torch.exp(x-z)+ torch.exp(y-z))"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1665560038084,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ZsrgvsFh8UFq","outputId":"e060a241-5894-4470-8f9c-4920c77bb3c7"},"outputs":[{"data":{"text/plain":["tensor([inf], grad_fn=<NegBackward0>)"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["log_exp(x, y)"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665560038084,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"3NoH9aa48Lzf","outputId":"25b335bd-adcd-4af3-9eb0-44664449a546"},"outputs":[{"data":{"text/plain":["tensor([50.], grad_fn=<AddBackward0>)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["stable_log_exp(x, y)"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665560038085,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"d1uQXi8AC3c5","outputId":"7a6fcf81-145f-4486-d0c9-393ab2f20900"},"outputs":[{"name":"stdout","output_type":"stream","text":["x.grad = tensor([-1.])\n","y.grad = tensor([1.])\n"]}],"source":["grad(stable_log_exp, x, y)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["0.1487"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["round(1.1387-0.99,4)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0.5720])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.tensor([0.29])\n","torch.sigmoid(a)"]},{"cell_type":"markdown","metadata":{"id":"KbtZq01Y_iqP"},"source":["# <font color = 'pickle'>**Q4 : Manual Backpropogation (5 Points)**\n","\n","For the network below update the weights using back propogation. \n","\n","<img src = \"https://drive.google.com/uc?export=view&id=1e1EI-N773mUtQJ0SQx5wlJJ1RaIQ4dZ2\" width =600 >\n","\n","- X1, x2 are inputs. The values of the inputs are provided.\n","- h1, h2 are hidden neurons. You will need to calculate the values of h1 and h2 in forward pass.\n","- o1 and o2 are outputs. 0.01 and 0.99 are the true values of the output. You will calculate the predicted values of o1 and o1 in forward pass.\n","- W1-W8 are weights. The initial values are provided to you. You will need to calculate the updated values in backward pass.\n","- bh1, bh2, bo1, bo2 are bias terms. The initial values are provided. You will need to calculate the updated values in backward pass.\n","\n","- You will apply sigmoid activation on hidden layer.\n","- You will apply Linear activation function on output neurons.\n","- You will use the  squared error as the loss function. \n","where <br>$ E_1 =1/2 *(\\hat{o_1}-o_1)^2 $ <br> \n","$ E_2 =1/2 *(\\hat{o_2}-o_2)^2 $ <br>  $ E = E_1 + E_2$\n","\n","Here $E$ is the total loss. $\\hat{o_2}$ and $\\hat{o_2}$ are predicted values of $o_1$ and $o_2$.\n"," \n","- <font color ='indianred'> **Assume a Learning Rate of 10.**\n","    \n","\n","<font size = 4 color ='indianred'> **Requirements**\n","- Show caluclations for one forward and one backward pass.\n","- Show all the steps of your calculations. You will get partial credit for the steps even if the final answers are not accurate.\n","- You will do this question manually.\n","- For this question you can submit - ppt  or pdf file (pdf of handwritten calculations)."]},{"cell_type":"markdown","metadata":{"id":"FDY2DaSip72l"},"source":["##  <font color = 'pickle'>**Q4 : Manual Backpropogation Solution**\n"]},{"cell_type":"markdown","metadata":{"id":"Y9YyIVBDEqZV"},"source":["###  <font color = 'pickle'>**Forward Pass**\n","\n","<img src = \"https://drive.google.com/uc?export=view&id=1k4GhDnulYPrOueTtAYEUeVrRWG4PMEjw\" width =600, height = 350 >\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["-0.3351"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["round(0.5 - 10*0.1486*0.562,4)"]},{"cell_type":"markdown","metadata":{"id":"Cmj7eaKXE5sL"},"source":["###  <font color = 'pickle'>**Backward Pass**\n","\n","<img src = \"https://drive.google.com/uc?export=view&id=1k5AE6KeOfYeXYo6x_RoLUEiUFi6dlt4w\" width =600, height = 350 >\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OrHh56SYEisJ"},"source":["## <font color = 'pickle'>**Q4 : Manual Backpropogation Solution Using PyTorch**"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665560038085,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"F1PvKOJZADES"},"outputs":[],"source":["x= torch.tensor([[0.0,0.3]]).float()"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665560038085,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"iHEPv28qAbi2","outputId":"c2fd375e-bdc4-4730-d6b9-ec134aee662d"},"outputs":[{"data":{"text/plain":["torch.Size([1, 2])"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["x.shape"]},{"cell_type":"code","execution_count":76,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665560038085,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"8Ti8Ez4sAcyN"},"outputs":[],"source":["y= torch.tensor([[0.01, 0.99]]).float()"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665560038085,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"wSrTvveNAkw6","outputId":"2e00e239-bb05-4995-853f-eb9bb5c24787"},"outputs":[{"data":{"text/plain":["torch.Size([1, 2])"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["y.shape"]},{"cell_type":"code","execution_count":78,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665560038086,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"DGLYRMK1AlqG"},"outputs":[],"source":["model1  = nn.Sequential(nn.Linear(2,2), nn.Sigmoid(), nn.Linear(2,2))"]},{"cell_type":"code","execution_count":79,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665560038086,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"tldC1qZXBDIp"},"outputs":[],"source":["model1[0].weight = torch.nn.Parameter(torch.tensor([[0.10, 0.50],[0.4, 0.30]]))\n","model1[0].bias = torch.nn.Parameter(torch.tensor([[0.1, 0.2]]))\n","model1[2].weight = torch.nn.Parameter(torch.tensor([[0.2, 0.60], [0.5, 0.8]]))\n","model1[2].bias = torch.nn.Parameter(torch.tensor([[0.3, 0.4]]))"]},{"cell_type":"code","execution_count":80,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665560038086,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Jag0oEn7BAuh"},"outputs":[],"source":["predy = model1(x)"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":224,"status":"ok","timestamp":1665560038304,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"6fpjFdC4GHJD","outputId":"464e0130-2e9f-4248-e7e3-dee403f5e6e8"},"outputs":[{"data":{"text/plain":["tensor([[0.7556, 1.1387]], grad_fn=<AddmmBackward0>)"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["predy"]},{"cell_type":"code","execution_count":82,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665560038304,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ZtaJCxvdJ9_t","outputId":"95ed1410-bb96-4fe6-9085-b161f4499fdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.weight Parameter containing:\n","tensor([[0.1000, 0.5000],\n","        [0.4000, 0.3000]], requires_grad=True)\n","0.bias Parameter containing:\n","tensor([[0.1000, 0.2000]], requires_grad=True)\n","2.weight Parameter containing:\n","tensor([[0.2000, 0.6000],\n","        [0.5000, 0.8000]], requires_grad=True)\n","2.bias Parameter containing:\n","tensor([[0.3000, 0.4000]], requires_grad=True)\n"]}],"source":["for name, parameter in model1.named_parameters():\n","  print(name, parameter)"]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665560038305,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Bb_Sj4INKLQW"},"outputs":[],"source":["optim = torch.optim.SGD(model1.parameters(), lr=10)"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665560038305,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"9gLc4_3FKsKN"},"outputs":[],"source":["criterion = nn.MSELoss(reduction='mean')"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665560038305,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"EuNnYeiFKzLR"},"outputs":[],"source":["loss = criterion(predy, y)"]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665560038305,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"KVjM0zs0LABc","outputId":"bbc72d69-e267-420e-fbc1-ce3df0f32d00"},"outputs":[{"data":{"text/plain":["tensor(0.2890, grad_fn=<MseLossBackward0>)"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["loss"]},{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665560038306,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"AkKWaXxcNF55","outputId":"0f89c8a5-9d2d-4900-d5a2-6543a46438f4"},"outputs":[{"data":{"text/plain":["tensor([[0.7456, 0.1487]], grad_fn=<SubBackward0>)"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["e=predy-y\n","e"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1665560038603,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"b9jU-V1lOCyO","outputId":"95a37710-d386-49eb-9ddc-d2c282847c8a"},"outputs":[{"data":{"text/plain":["tensor(0.2890, grad_fn=<MulBackward0>)"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["0.5*(e*e).sum()"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665560038603,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Fyrch6S5LCjK"},"outputs":[],"source":["loss.backward()"]},{"cell_type":"code","execution_count":90,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665560038603,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"O4QkGRbOMMa7"},"outputs":[],"source":["optim.step()"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665560038603,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"aDA1uy_vMcSo","outputId":"dca434b7-9bbd-468e-b6ff-d95e94a59c33"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.weight Parameter containing:\n","tensor([[ 0.1000,  0.3350],\n","        [ 0.4000, -0.1159]], requires_grad=True)\n","0.bias Parameter containing:\n","tensor([[-0.4500, -1.1865]], requires_grad=True)\n","2.weight Parameter containing:\n","tensor([[-3.9918, -3.6650],\n","        [-0.3359, -0.0505]], requires_grad=True)\n","2.bias Parameter containing:\n","tensor([[-7.1563, -1.0869]], requires_grad=True)\n"]}],"source":["for name, parameter in model1.named_parameters():\n","  print(name, parameter)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"fa6fc890c19d0518efc3ca8fefe1ab7c2a921b84ac247755bf14d3f8c1bb1ece"}}},"nbformat":4,"nbformat_minor":0}
